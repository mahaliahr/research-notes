---
kanban-plugin: board
dg-publish: true
title: llm supervisor v1 progress
permalink: /notes/llm-supervisor-v1-progress/
visibility: public
description: "## \U0001F4A1In Progress\n\n\n\n## Setup\n\n\n\n## Input\n\n- [ ] Store transcript with timestamp in CSV/JSON\n\n\n## Logic + Processing\n\n- [ ] Add recent messages as context (simpl"
updated: '2025-10-20T22:34:14.458Z'
---

## üí°In Progress



## Setup



## Input

- [ ] Store transcript with timestamp in CSV/JSON


## Logic + Processing

- [ ] Add recent messages as context (simple memory)
- [ ] Implement logic for LLM to "respond to a conversation"
- [ ] Try out a second persona for contrast


## UI

- [ ] - Build a simple UI (Streamlit, notebook, or CLI)
	    
	- Display conversation log
	    
	- Add new input field (or simulate with logs)
- [ ] Display conversation log
- [ ] Add new input field (or simulate with logs)


## Presentation and Reflection

- [ ] - Write a reflective note (What worked? What next?)
- [ ] - Share with your supervisors


## ‚òëÔ∏è Done

- [x] - Record a short video of the system in action
- [x] Do some research into how to use Whisper for realtime transcription
- [x] Create a basic prompt template with role/context
- [ ] Write a 3-sentence scope for your prototype
- [ ] Install Ollama or LM Studio locally
- [ ] Run a test chat with a small model (e.g., Mistral or Phi)
- [ ] Install Whisper or whisper.cpp
- [ ] Choose your first LLM persona and write its prompt
- [ ] Decide on text or voice input (or both)
- [x] Write a script to transcribe and save input




%% kanban:settings
```
{"kanban-plugin":"board","list-collapse":[false,false,false,false,false,false,false],"tag-colors":[{"tagKey":"","color":"","backgroundColor":""}],"archive-with-date":true,"show-view-as-markdown":false,"show-checkboxes":true}
```
%%
